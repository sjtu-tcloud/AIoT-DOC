{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cc/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/cc/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/cc/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/cc/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/cc/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/cc/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./dog.png\n",
      "./mobilenet_v1_1.0_224_frozen.pb\n",
      "./label.txt\n",
      "INFO:tensorflow:Froze 0 variables.\n",
      "INFO:tensorflow:Converted 0 variables to const ops.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Attribute use_cudnn_on_gpu is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute T is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute _output_shapes is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute _node_name is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute _target_layout is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute data_format is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute _output_shapes is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute is_training is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute T is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute _node_name is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute _target_layout is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute _output_shapes is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute T is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute _node_name is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute _target_layout is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute _output_shapes is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute is_training is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute T is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute data_format is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute _node_name is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute _target_layout is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute use_cudnn_on_gpu is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute _output_shapes is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute T is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute _node_name is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute _target_layout is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute data_format is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute is_training is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute T is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute _output_shapes is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute _node_name is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute _target_layout is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute T is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute _output_shapes is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute _node_name is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute _target_layout is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute data_format is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute is_training is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute T is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute _output_shapes is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute _node_name is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute _target_layout is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute T is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute _output_shapes is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute use_cudnn_on_gpu is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute _node_name is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute _target_layout is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute T is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute is_training is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute data_format is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute _output_shapes is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute _node_name is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute _target_layout is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute _output_shapes is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute T is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute _node_name is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute _target_layout is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute T is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute is_training is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute _output_shapes is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute data_format is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute _node_name is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute _target_layout is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute _output_shapes is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute T is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute use_cudnn_on_gpu is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute _node_name is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute _target_layout is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute is_training is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute data_format is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute _output_shapes is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute T is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute _node_name is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute _target_layout is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute _output_shapes is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute T is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute _node_name is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute _target_layout is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute data_format is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute _output_shapes is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute is_training is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute T is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute _node_name is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute _target_layout is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute _output_shapes is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute T is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute use_cudnn_on_gpu is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute _node_name is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute _target_layout is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute _output_shapes is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute T is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute is_training is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute data_format is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute _node_name is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute _target_layout is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute T is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute _output_shapes is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute _node_name is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute _target_layout is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute data_format is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute T is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute is_training is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute _output_shapes is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute _node_name is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute _target_layout is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute use_cudnn_on_gpu is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute T is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute _output_shapes is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute _node_name is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute _target_layout is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute T is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute data_format is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute _output_shapes is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute is_training is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute _node_name is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute _target_layout is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute T is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute _output_shapes is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute _node_name is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute _target_layout is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute is_training is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute T is ignored in relay.sym.batch_norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Attribute _output_shapes is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute data_format is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute _node_name is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute _target_layout is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute use_cudnn_on_gpu is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute _output_shapes is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute T is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute _node_name is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute _target_layout is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute T is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute _output_shapes is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute is_training is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute data_format is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute _node_name is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute _target_layout is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute _output_shapes is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute T is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute _node_name is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute _target_layout is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute _output_shapes is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute data_format is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute is_training is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute T is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute _node_name is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute _target_layout is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute T is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute _output_shapes is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute use_cudnn_on_gpu is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute _node_name is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute _target_layout is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute T is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute data_format is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute is_training is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute _output_shapes is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute _node_name is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute _target_layout is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute _output_shapes is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute T is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute _node_name is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute _target_layout is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute _output_shapes is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute T is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute is_training is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute data_format is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute _node_name is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute _target_layout is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute _output_shapes is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute use_cudnn_on_gpu is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute T is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute _node_name is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute _target_layout is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute _output_shapes is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute is_training is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute data_format is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute T is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute _node_name is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute _target_layout is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute _output_shapes is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute T is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute _node_name is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute _target_layout is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute T is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute _output_shapes is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute data_format is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute is_training is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute _node_name is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute _target_layout is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute _output_shapes is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute T is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute use_cudnn_on_gpu is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute _node_name is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute _target_layout is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute T is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute data_format is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute _output_shapes is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute is_training is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute _node_name is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute _target_layout is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute _output_shapes is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute T is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute _node_name is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute _target_layout is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute data_format is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute T is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute _output_shapes is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute is_training is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute _node_name is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute _target_layout is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute T is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute _output_shapes is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute use_cudnn_on_gpu is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute _node_name is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute _target_layout is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute data_format is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute is_training is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute _output_shapes is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute T is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute _node_name is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute _target_layout is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute T is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute _output_shapes is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute _node_name is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute _target_layout is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute _output_shapes is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute data_format is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute T is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute is_training is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute _node_name is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute _target_layout is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute use_cudnn_on_gpu is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute T is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute _output_shapes is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute _node_name is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute _target_layout is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute is_training is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute _output_shapes is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute data_format is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute T is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute _node_name is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute _target_layout is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute _output_shapes is ignored in relay.sym.conv2d\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Attribute T is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute _node_name is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute _target_layout is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute T is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute _output_shapes is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute is_training is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute data_format is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute _node_name is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute _target_layout is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute _output_shapes is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute T is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute use_cudnn_on_gpu is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute _node_name is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute _target_layout is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute _output_shapes is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute is_training is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute T is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute data_format is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute _node_name is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute _target_layout is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute _output_shapes is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute T is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute _node_name is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute _target_layout is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute data_format is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute T is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute _output_shapes is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute is_training is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute _node_name is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute _target_layout is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute use_cudnn_on_gpu is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute _output_shapes is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute T is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute _node_name is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute _target_layout is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute _output_shapes is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute is_training is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute T is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute data_format is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute _node_name is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute _target_layout is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute _output_shapes is ignored in relay.sym.avg_pool2d\n",
      "WARNING:root:Attribute T is ignored in relay.sym.avg_pool2d\n",
      "WARNING:root:Attribute ksize is ignored in relay.sym.avg_pool2d\n",
      "WARNING:root:Attribute _node_name is ignored in relay.sym.avg_pool2d\n",
      "WARNING:root:Attribute _target_layout is ignored in relay.sym.avg_pool2d\n",
      "WARNING:root:Attribute T is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute use_cudnn_on_gpu is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute _output_shapes is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute _node_name is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute _target_layout is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute _output_shapes is ignored in relay.sym.squeeze\n",
      "WARNING:root:Attribute T is ignored in relay.sym.squeeze\n",
      "WARNING:root:Attribute _node_name is ignored in relay.sym.squeeze\n",
      "WARNING:root:Attribute _target_layout is ignored in relay.sym.squeeze\n",
      "WARNING:root:Attribute T is ignored in relay.sym.reshape\n",
      "WARNING:root:Attribute _output_shapes is ignored in relay.sym.reshape\n",
      "WARNING:root:Attribute Tshape is ignored in relay.sym.reshape\n",
      "WARNING:root:Attribute _node_name is ignored in relay.sym.reshape\n",
      "WARNING:root:Attribute _target_layout is ignored in relay.sym.reshape\n",
      "WARNING:root:Attribute T is ignored in relay.sym.softmax\n",
      "WARNING:root:Attribute _output_shapes is ignored in relay.sym.softmax\n",
      "WARNING:root:Attribute _node_name is ignored in relay.sym.softmax\n",
      "WARNING:root:Attribute _target_layout is ignored in relay.sym.softmax\n",
      "WARNING:root:Attribute Tshape is ignored in relay.sym.reshape\n",
      "WARNING:root:Attribute T is ignored in relay.sym.reshape\n",
      "WARNING:root:Attribute _output_shapes is ignored in relay.sym.reshape\n",
      "WARNING:root:Attribute _node_name is ignored in relay.sym.reshape\n",
      "WARNING:root:Attribute _target_layout is ignored in relay.sym.reshape\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow protobuf imported to relay frontend.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:strategy:For x86 target, NCHW layout is recommended for conv2d.\n",
      "WARNING:strategy:depthwise_conv2d NHWC layout is not optimized for x86.\n",
      "WARNING:strategy:For x86 target, NCHW layout is recommended for conv2d.\n",
      "WARNING:strategy:depthwise_conv2d NHWC layout is not optimized for x86.\n",
      "WARNING:strategy:For x86 target, NCHW layout is recommended for conv2d.\n",
      "WARNING:strategy:depthwise_conv2d NHWC layout is not optimized for x86.\n",
      "WARNING:strategy:For x86 target, NCHW layout is recommended for conv2d.\n",
      "WARNING:strategy:depthwise_conv2d NHWC layout is not optimized for x86.\n",
      "WARNING:strategy:For x86 target, NCHW layout is recommended for conv2d.\n",
      "WARNING:strategy:depthwise_conv2d NHWC layout is not optimized for x86.\n",
      "WARNING:strategy:For x86 target, NCHW layout is recommended for conv2d.\n",
      "WARNING:strategy:depthwise_conv2d NHWC layout is not optimized for x86.\n",
      "WARNING:strategy:For x86 target, NCHW layout is recommended for conv2d.\n",
      "WARNING:strategy:depthwise_conv2d NHWC layout is not optimized for x86.\n",
      "WARNING:strategy:For x86 target, NCHW layout is recommended for conv2d.\n",
      "WARNING:strategy:depthwise_conv2d NHWC layout is not optimized for x86.\n",
      "WARNING:strategy:For x86 target, NCHW layout is recommended for conv2d.\n",
      "WARNING:strategy:depthwise_conv2d NHWC layout is not optimized for x86.\n",
      "WARNING:strategy:For x86 target, NCHW layout is recommended for conv2d.\n",
      "WARNING:strategy:depthwise_conv2d NHWC layout is not optimized for x86.\n",
      "WARNING:strategy:For x86 target, NCHW layout is recommended for conv2d.\n",
      "WARNING:strategy:depthwise_conv2d NHWC layout is not optimized for x86.\n",
      "WARNING:strategy:For x86 target, NCHW layout is recommended for conv2d.\n",
      "WARNING:strategy:depthwise_conv2d NHWC layout is not optimized for x86.\n",
      "WARNING:strategy:For x86 target, NCHW layout is recommended for conv2d.\n",
      "WARNING:strategy:depthwise_conv2d NHWC layout is not optimized for x86.\n",
      "WARNING:strategy:For x86 target, NCHW layout is recommended for conv2d.\n",
      "WARNING:strategy:For x86 target, NCHW layout is recommended for conv2d.\n",
      "WARNING:strategy:For x86 target, NCHW layout is recommended for conv2d.\n",
      "WARNING:strategy:For x86 target, NCHW layout is recommended for conv2d.\n",
      "WARNING:strategy:depthwise_conv2d NHWC layout is not optimized for x86.\n",
      "WARNING:strategy:For x86 target, NCHW layout is recommended for conv2d.\n",
      "WARNING:strategy:depthwise_conv2d NHWC layout is not optimized for x86.\n",
      "WARNING:strategy:For x86 target, NCHW layout is recommended for conv2d.\n",
      "WARNING:strategy:depthwise_conv2d NHWC layout is not optimized for x86.\n",
      "WARNING:strategy:For x86 target, NCHW layout is recommended for conv2d.\n",
      "WARNING:strategy:depthwise_conv2d NHWC layout is not optimized for x86.\n",
      "WARNING:strategy:For x86 target, NCHW layout is recommended for conv2d.\n",
      "WARNING:strategy:depthwise_conv2d NHWC layout is not optimized for x86.\n",
      "WARNING:strategy:For x86 target, NCHW layout is recommended for conv2d.\n",
      "WARNING:strategy:depthwise_conv2d NHWC layout is not optimized for x86.\n",
      "WARNING:strategy:For x86 target, NCHW layout is recommended for conv2d.\n",
      "WARNING:strategy:depthwise_conv2d NHWC layout is not optimized for x86.\n",
      "WARNING:strategy:For x86 target, NCHW layout is recommended for conv2d.\n",
      "WARNING:strategy:depthwise_conv2d NHWC layout is not optimized for x86.\n",
      "WARNING:strategy:For x86 target, NCHW layout is recommended for conv2d.\n",
      "WARNING:strategy:depthwise_conv2d NHWC layout is not optimized for x86.\n",
      "WARNING:strategy:For x86 target, NCHW layout is recommended for conv2d.\n",
      "/home/cc/.local/lib/python3.6/site-packages/ipykernel_launcher.py:143: DeprecationWarning: legacy graph runtime behaviour of producing json / lib / params will be removed in the next release \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== TVM RESULTS =======\n",
      "0.102707s\n",
      "[ 208]金毛猎犬: 0.56103\n",
      "[ 209]拉布拉多猎犬: 0.39044\n",
      "[ 220]可卡犬: 0.02364\n",
      "[ 223]哥威斯犬: 0.01085\n",
      "[ 217]黄毛: 0.00124\n",
      "===== TENSORFLOW RESULTS =======\n",
      "0.269801s\n",
      "[ 208]金毛猎犬: 0.56103\n",
      "[ 209]拉布拉多猎犬: 0.39044\n",
      "[ 220]可卡犬: 0.02364\n",
      "[ 223]哥威斯犬: 0.01085\n",
      "[ 217]黄毛: 0.00124\n"
     ]
    }
   ],
   "source": [
    "# Licensed to the Apache Software Foundation (ASF) under one\n",
    "# or more contributor license agreements.  See the NOTICE file\n",
    "# distributed with this work for additional information\n",
    "# regarding copyright ownership.  The ASF licenses this file\n",
    "# to you under the Apache License, Version 2.0 (the\n",
    "# \"License\"); you may not use this file except in compliance\n",
    "# with the License.  You may obtain a copy of the License at\n",
    "#\n",
    "#   http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing,\n",
    "# software distributed under the License is distributed on an\n",
    "# \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n",
    "# KIND, either express or implied.  See the License for the\n",
    "# specific language governing permissions and limitations\n",
    "# under the License.\n",
    "\"\"\"\n",
    "Compile Tensorflow Models\n",
    "=========================\n",
    "This article is an introductory tutorial to deploy tensorflow models with TVM.\n",
    "\n",
    "For us to begin with, tensorflow python module is required to be installed.\n",
    "\n",
    "Please refer to https://www.tensorflow.org/install\n",
    "\"\"\"\n",
    "\n",
    "# tvm, relay\n",
    "import tvm\n",
    "from tvm import te\n",
    "from tvm import relay\n",
    "\n",
    "# os and numpy\n",
    "import numpy as np\n",
    "import os.path\n",
    "\n",
    "# Tensorflow imports\n",
    "import tensorflow as tf\n",
    "tf_compat_v1 = tf\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "# Tensorflow utility functions\n",
    "import tvm.relay.testing.tf as tf_testing\n",
    "\n",
    "# Base location for model related files.\n",
    "repo_base = '.'\n",
    "\n",
    "# Test image\n",
    "img_name = 'dog.png'\n",
    "img_path = os.path.join(repo_base, img_name)\n",
    "\n",
    "model_path = os.path.join(repo_base, 'mobilenet_v1_1.0_224_frozen.pb')\n",
    "label_path = os.path.join(repo_base, 'label.txt')\n",
    "\n",
    "print(img_path)\n",
    "print(model_path)\n",
    "print(label_path)\n",
    "\n",
    "def load_label():\n",
    "    label=['Background']\n",
    "    with open(label_path,'r',encoding='utf-8') as r:\n",
    "        lines = r.readlines()\n",
    "        for l in lines:\n",
    "            l = l.strip()\n",
    "            arr = l.split(',')\n",
    "            label.append(arr[1])\n",
    "    return label\n",
    "\n",
    "label = load_label()\n",
    "\n",
    "# Target settings\n",
    "# Use these commented settings to build for cuda.\n",
    "#target = 'cuda'\n",
    "#target_host = 'llvm'\n",
    "#layout = \"NCHW\"\n",
    "#ctx = tvm.gpu(0)\n",
    "target = 'llvm'\n",
    "target_host = 'llvm'\n",
    "layout = None\n",
    "ctx = tvm.cpu(0)\n",
    "\n",
    "######################################################################\n",
    "# Import model\n",
    "# ------------\n",
    "# Creates tensorflow graph definition from protobuf file.\n",
    "\n",
    "with tf_compat_v1.gfile.GFile(model_path, 'rb') as f:\n",
    "    graph_def = tf_compat_v1.GraphDef()\n",
    "    graph_def.ParseFromString(f.read())\n",
    "    graph = tf.import_graph_def(graph_def, name='')\n",
    "    # Call the utility to import the graph definition into default graph.\n",
    "    graph_def = tf_testing.ProcessGraphDefParam(graph_def)\n",
    "    # Add shapes to the graph.\n",
    "    with tf_compat_v1.Session() as sess:\n",
    "        graph_def = tf_testing.AddShapesToGraphDef(sess, 'MobilenetV1/Predictions/Reshape_1')\n",
    "\n",
    "######################################################################\n",
    "# Decode image\n",
    "# ------------\n",
    "# .. note::\n",
    "#\n",
    "#   tensorflow frontend import doesn't support preprocessing ops like JpegDecode.\n",
    "#   JpegDecode is bypassed (just return source node).\n",
    "#   Hence we supply decoded frame to TVM instead.\n",
    "#\n",
    "\n",
    "from PIL import Image\n",
    "image = Image.open(img_path).resize((224, 224))\n",
    "\n",
    "x = np.array(image)\n",
    "#print(x.shape)\n",
    "x = np.expand_dims(x,axis=0)\n",
    "x = (x/255.0-0.5)*2.0\n",
    "#print(x)\n",
    "\n",
    "######################################################################\n",
    "# Import the graph to Relay\n",
    "# -------------------------\n",
    "# Import tensorflow graph definition to relay frontend.\n",
    "#\n",
    "# Results:\n",
    "#   sym: relay expr for given tensorflow protobuf.\n",
    "#   params: params converted from tensorflow params (tensor protobuf).\n",
    "shape_dict = {'input': (1,224,224,3)}\n",
    "#dtype_dict = {'DecodeJpeg/contents': 'uint8'}\n",
    "mod, params = relay.frontend.from_tensorflow(graph_def,\n",
    "                                             layout=layout,\n",
    "                                             shape=shape_dict)\n",
    "\n",
    "print(\"Tensorflow protobuf imported to relay frontend.\")\n",
    "######################################################################\n",
    "# Relay Build\n",
    "# -----------\n",
    "# Compile the graph to llvm target with given input specification.\n",
    "#\n",
    "# Results:\n",
    "#   graph: Final graph after compilation.\n",
    "#   params: final params after compilation.\n",
    "#   lib: target library which can be deployed on target with TVM runtime.\n",
    "\n",
    "with tvm.transform.PassContext(opt_level=3):\n",
    "#    lib = relay.build(mod, target=target, target_host=target_host, params=params)\n",
    "    graph, lib, params = relay.build(mod, target=target, target_host=target_host, params=params)\n",
    "\n",
    "# save the graph, lib and params into separate files\n",
    "from tvm.contrib import util\n",
    "\n",
    "lib.export_library(\"deploy_lib.tar\")\n",
    "with open(\"deploy_graph.json\", \"w\") as fo:\n",
    "    fo.write(graph)\n",
    "with open(\"deploy_param.params\", \"wb\") as fo:\n",
    "    fo.write(relay.save_param_dict(params))\n",
    "\n",
    "######################################################################\n",
    "# Execute the portable graph on TVM\n",
    "# ---------------------------------\n",
    "# Now we can try deploying the compiled model on target.\n",
    "\n",
    "from tvm.contrib import graph_runtime\n",
    "#m = graph_runtime.GraphModule(lib['default'](ctx))\n",
    "\n",
    "# load the module back.\n",
    "loaded_json = open(\"deploy_graph.json\").read()\n",
    "loaded_lib = tvm.runtime.load_module(\"deploy_lib.tar\")\n",
    "loaded_params = bytearray(open(\"deploy_param.params\", \"rb\").read())\n",
    "\n",
    "m = graph_runtime.create(loaded_json, loaded_lib, ctx)\n",
    "m.load_params(loaded_params)\n",
    "\n",
    "# set inputs\n",
    "m.set_input('input', tvm.nd.array(x.astype('float32')))\n",
    "# execute\n",
    "a=datetime.now()\n",
    "m.run()\n",
    "b=datetime.now()\n",
    "print (\"===== TVM RESULTS =======\")\n",
    "print(\"%d.%ds\" %((b-a).seconds, (b-a).microseconds))\n",
    "\n",
    "# get outputs\n",
    "tvm_output = m.get_output(0, tvm.nd.empty(((1, 1001)), 'float32'))\n",
    "\n",
    "######################################################################\n",
    "# Process the output\n",
    "# ------------------\n",
    "# Process the model output to human readable text for InceptionV1.\n",
    "predictions = tvm_output.asnumpy()\n",
    "predictions = np.squeeze(predictions)\n",
    "\n",
    "# Print top 5 predictions from TVM output.\n",
    "top_k = predictions.argsort()[-5:][::-1]\n",
    "for node_id in top_k:\n",
    "    score = predictions[node_id]\n",
    "    print('[%4d]%s: %.5f' % (node_id, label[node_id], score))\n",
    "######################################################################\n",
    "# Inference on tensorflow\n",
    "# -----------------------\n",
    "# Run the corresponding model on tensorflow\n",
    "\n",
    "def create_graph():\n",
    "    \"\"\"Creates a graph from saved GraphDef file and returns a saver.\"\"\"\n",
    "    # Creates graph from saved graph_def.pb.\n",
    "    with tf_compat_v1.gfile.GFile(model_path, 'rb') as f:\n",
    "        graph_def = tf_compat_v1.GraphDef()\n",
    "        graph_def.ParseFromString(f.read())\n",
    "        graph = tf.import_graph_def(graph_def, name='')\n",
    "        # Call the utility to import the graph definition into default graph.\n",
    "        graph_def = tf_testing.ProcessGraphDefParam(graph_def)\n",
    "\n",
    "def run_inference_on_image(image):\n",
    "    \"\"\"Runs inference on an image.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    image: String\n",
    "        Image file name.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        Nothing\n",
    "    \"\"\"\n",
    "#    if not tf_compat_v1.gfile.Exists(image):\n",
    "#        tf.logging.fatal('File does not exist %s', image)\n",
    "#    image_data = tf_compat_v1.gfile.GFile(image, 'rb').read()\n",
    "    image_data = x\n",
    "\n",
    "    # Creates graph from saved GraphDef.\n",
    "    create_graph()\n",
    "\n",
    "    with tf_compat_v1.Session() as sess:\n",
    "        softmax_tensor = sess.graph.get_tensor_by_name('MobilenetV1/Predictions/Reshape_1:0')\n",
    "        a=datetime.now()\n",
    "        predictions = sess.run(softmax_tensor,\n",
    "                               {'input:0': image_data})\n",
    "        b=datetime.now()\n",
    "        print (\"===== TENSORFLOW RESULTS =======\")\n",
    "        print(\"%d.%ds\" %((b-a).seconds, (b-a).microseconds))\n",
    "        predictions = np.squeeze(predictions)\n",
    "\n",
    "        # Print top 5 predictions from tensorflow.\n",
    "        top_k = predictions.argsort()[-5:][::-1]\n",
    "        for node_id in top_k:\n",
    "            score = predictions[node_id]\n",
    "            print('[%4d]%s: %.5f' % (node_id, label[node_id], score))\n",
    "\n",
    "run_inference_on_image(img_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
