{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cc/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/cc/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/cc/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/cc/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/cc/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/cc/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(224, 224, 3)\n",
      "(1, 224, 224, 3) <class 'numpy.ndarray'> float32 True\n",
      "===== Tensorflow RESULTS =======\n",
      "0.58434s\n",
      "[ 208]金毛猎犬: 0.56103\n",
      "[ 209]拉布拉多猎犬: 0.39044\n",
      "[ 220]可卡犬: 0.02364\n",
      "[ 223]哥威斯犬: 0.01085\n",
      "[ 217]黄毛: 0.00124\n"
     ]
    }
   ],
   "source": [
    "# os and numpy\n",
    "import numpy as np\n",
    "import os.path\n",
    "\n",
    "# Tensorflow imports\n",
    "import tensorflow as tf\n",
    "\n",
    "#for count time\n",
    "from datetime import datetime\n",
    "\n",
    "# Base location for model related files.\n",
    "repo_base = '.'\n",
    "\n",
    "# Test image\n",
    "img_name = 'dog.png'\n",
    "img_path = os.path.join(repo_base, img_name)\n",
    "\n",
    "model_name = 'mobilenet_v1_1.0_224_frozen.pb'\n",
    "model_path = os.path.join(repo_base, model_name)\n",
    "\n",
    "# Human readable text for labels\n",
    "label_map = 'label.txt'\n",
    "label_path = os.path.join(repo_base, label_map)\n",
    "\n",
    "# Saved model from origional model's pb\n",
    "inputs = ['input']\n",
    "outputs = ['MobilenetV1/Predictions/Reshape_1']\n",
    "converter = tf.contrib.lite.TFLiteConverter.from_frozen_graph(model_name, inputs, outputs,\n",
    "             input_shapes={\"input\": [1, 224, 224, 3]})\n",
    "tflite_model = converter.convert()\n",
    "open(\"converted_model.tflite\", \"wb\").write(tflite_model)\n",
    "\n",
    "######################################################################################\n",
    "\n",
    "#print(img_path)\n",
    "#print(model_path)\n",
    "#print(label_path)\n",
    "\n",
    "def load_label():\n",
    "    label=['Background']\n",
    "    with open(label_path,'r',encoding='utf-8') as r:\n",
    "        lines = r.readlines()\n",
    "        for l in lines:\n",
    "            l = l.strip()\n",
    "            arr = l.split(',')\n",
    "            label.append(arr[1])\n",
    "    return label\n",
    "\n",
    "label = load_label()\n",
    "\n",
    "######################################################################\n",
    "#Load Img and pre-process\n",
    "from PIL import Image\n",
    "image = Image.open(img_path).resize((224, 224))\n",
    "# image.show()\n",
    "\n",
    "x = np.array(image)\n",
    "x = x.astype('float32')\n",
    "print(x.shape)\n",
    "#print(x)\n",
    "x = (x/255.0-0.5)*2.0\n",
    "x = np.expand_dims(x,axis=0)\n",
    "x = x.astype(np.float32)\n",
    "if not x.flags['C_CONTIGUOUS']:\n",
    "    x = np.ascontiguousarray(x, dtype=x.dtype)\n",
    "print(x.shape, type(x), x.dtype, x.flags['C_CONTIGUOUS'])\n",
    "\n",
    "######################################################################\n",
    "# Inference on tensorflow\n",
    "# -----------------------\n",
    "# Run the corresponding model on tensorflow lite\n",
    "\n",
    "def run_inference_on_image(image):\n",
    "\n",
    "    image_data = x\n",
    "\n",
    "    interpreter = tf.contrib.lite.Interpreter(\"converted_model.tflite\")\n",
    "    interpreter.allocate_tensors()\n",
    "\n",
    "# Get input and output tensors\n",
    "    input_details = interpreter.get_input_details()\n",
    "    output_details = interpreter.get_output_details()\n",
    "\n",
    "    interpreter.set_tensor(input_details[0]['index'], x)\n",
    "    a=datetime.now()\n",
    "    interpreter.invoke()\n",
    "    b=datetime.now()\n",
    "    print (\"===== Tensorflow RESULTS =======\")\n",
    "    print(\"%d.%ds\" %((b-a).seconds, (b-a).microseconds))\n",
    "\n",
    "    predictions = interpreter.get_tensor(output_details[0]['index'])\n",
    "    predictions = np.squeeze(predictions)\n",
    "\n",
    "# Print top 5 predictions from tensorflow.\n",
    "    top_k = predictions.argsort()[-5:][::-1]\n",
    "    for node_id in top_k:\n",
    "        score = predictions[node_id]\n",
    "        print('[%4d]%s: %.5f' % (node_id, label[node_id], score))\n",
    "\n",
    "run_inference_on_image(img_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
