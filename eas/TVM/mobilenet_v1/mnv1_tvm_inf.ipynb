{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cc/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/cc/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/cc/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/cc/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/cc/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/cc/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== TVM RESULTS =======\n",
      "0.145703s\n",
      "[ 208]金毛猎犬: 0.56103\n",
      "[ 209]拉布拉多猎犬: 0.39044\n",
      "[ 220]可卡犬: 0.02364\n",
      "[ 223]哥威斯犬: 0.01085\n",
      "[ 217]黄毛: 0.00124\n"
     ]
    }
   ],
   "source": [
    "# Licensed to the Apache Software Foundation (ASF) under one\n",
    "# or more contributor license agreements.  See the NOTICE file\n",
    "# distributed with this work for additional information\n",
    "# regarding copyright ownership.  The ASF licenses this file\n",
    "# to you under the Apache License, Version 2.0 (the\n",
    "# \"License\"); you may not use this file except in compliance\n",
    "# with the License.  You may obtain a copy of the License at\n",
    "#\n",
    "#   http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing,\n",
    "# software distributed under the License is distributed on an\n",
    "# \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n",
    "# KIND, either express or implied.  See the License for the\n",
    "# specific language governing permissions and limitations\n",
    "# under the License.\n",
    "\"\"\"\n",
    "Compile Tensorflow Models\n",
    "=========================\n",
    "This article is an introductory tutorial to deploy tensorflow models with TVM.\n",
    "\n",
    "For us to begin with, tensorflow python module is required to be installed.\n",
    "\n",
    "Please refer to https://www.tensorflow.org/install\n",
    "\"\"\"\n",
    "\n",
    "# tvm, relay\n",
    "import tvm\n",
    "from tvm import te\n",
    "from tvm import relay\n",
    "\n",
    "# os and numpy\n",
    "import numpy as np\n",
    "import os.path\n",
    "\n",
    "# Tensorflow imports\n",
    "import tensorflow as tf\n",
    "tf_compat_v1 = tf\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "# Tensorflow utility functions\n",
    "import tvm.relay.testing.tf as tf_testing\n",
    "\n",
    "# Base location for model related files.\n",
    "repo_base = '.'\n",
    "\n",
    "# Test image\n",
    "img_name = 'dog.png'\n",
    "img_path = os.path.join(repo_base, img_name)\n",
    "\n",
    "model_path = os.path.join(repo_base, 'mobilenet_v1_1.0_224_frozen.pb')\n",
    "label_path = os.path.join(repo_base, 'label.txt')\n",
    "\n",
    "def load_label():\n",
    "    label=['Background']\n",
    "    with open(label_path,'r',encoding='utf-8') as r:\n",
    "        lines = r.readlines()\n",
    "        for l in lines:\n",
    "            l = l.strip()\n",
    "            arr = l.split(',')\n",
    "            label.append(arr[1])\n",
    "    return label\n",
    "\n",
    "label = load_label()\n",
    "\n",
    "# Target settings\n",
    "# Use these commented settings to build for cuda.\n",
    "#target = 'cuda'\n",
    "#target_host = 'llvm'\n",
    "#layout = \"NCHW\"\n",
    "#ctx = tvm.gpu(0)\n",
    "target = 'llvm'\n",
    "target_host = 'llvm'\n",
    "layout = None\n",
    "ctx = tvm.cpu(0)\n",
    "\n",
    "######################################################################\n",
    "# Decode image\n",
    "# ------------\n",
    "# .. note::\n",
    "#\n",
    "#   tensorflow frontend import doesn't support preprocessing ops like JpegDecode.\n",
    "#   JpegDecode is bypassed (just return source node).\n",
    "#   Hence we supply decoded frame to TVM instead.\n",
    "#\n",
    "\n",
    "from PIL import Image\n",
    "image = Image.open(img_path).resize((224, 224))\n",
    "\n",
    "x = np.array(image)\n",
    "#print(x.shape)\n",
    "x = np.expand_dims(x,axis=0)\n",
    "x = (x/255.0-0.5)*2.0\n",
    "#print(x)\n",
    "\n",
    "######################################################################\n",
    "# Execute the portable graph on TVM\n",
    "# ---------------------------------\n",
    "# Now we can try deploying the compiled model on target.\n",
    "\n",
    "from tvm.contrib import graph_runtime\n",
    "#m = graph_runtime.GraphModule(lib['default'](ctx))\n",
    "\n",
    "# load the module back.\n",
    "loaded_json = open(\"deploy_graph.json\").read()\n",
    "loaded_lib = tvm.runtime.load_module(\"deploy_lib.tar\")\n",
    "loaded_params = bytearray(open(\"deploy_param.params\", \"rb\").read())\n",
    "\n",
    "m = graph_runtime.create(loaded_json, loaded_lib, ctx)\n",
    "m.load_params(loaded_params)\n",
    "\n",
    "# set inputs\n",
    "m.set_input('input', tvm.nd.array(x.astype('float32')))\n",
    "# execute\n",
    "a=datetime.now()\n",
    "m.run()\n",
    "b=datetime.now()\n",
    "print (\"===== TVM RESULTS =======\")\n",
    "print(\"%d.%ds\" %((b-a).seconds, (b-a).microseconds))\n",
    "\n",
    "# get outputs\n",
    "tvm_output = m.get_output(0, tvm.nd.empty(((1, 1001)), 'float32'))\n",
    "\n",
    "######################################################################\n",
    "# Process the output\n",
    "# ------------------\n",
    "# Process the model output to human readable text for InceptionV1.\n",
    "predictions = tvm_output.asnumpy()\n",
    "predictions = np.squeeze(predictions)\n",
    "\n",
    "# Print top 5 predictions from TVM output.\n",
    "top_k = predictions.argsort()[-5:][::-1]\n",
    "for node_id in top_k:\n",
    "    score = predictions[node_id]\n",
    "    print('[%4d]%s: %.5f' % (node_id, label[node_id], score))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
